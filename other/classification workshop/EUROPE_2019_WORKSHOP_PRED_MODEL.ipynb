{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Welcome to our Hands-On Workshop! We'll mostly be exploring classification (predictive modeling) as a\n",
    "# way to study and analyze corpora of literary texts, poetry in particular.\n",
    "\n",
    "##### INSTALLATION!\n",
    "\n",
    "#### If you haven't installed Python yet, I'd like you to download and install the Anaconda distribution, which\n",
    "# can be found here: https://docs.anaconda.com/anaconda/install/\n",
    "# There are options for both MAC and Windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATA!\n",
    "\n",
    "# I circulated a link to the data in preparation for this workshop. Please download the data and put it somewhere\n",
    "# you can find on your machine. The data is out of copyright by American standards, so you are free to share it or\n",
    "# use it.\n",
    "\n",
    "# A word or two about MASSES versus OTHERS, two important American literary journals from the Modernist period\n",
    "# i.e, 1910 to 1925 or so. Masses was an important left-wing, proletarian journal; Others was a flagship journal\n",
    "# of high modernism, especially Imagism. TS Eliot, Pound, Amy Lowell all published there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POEM TITLE</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>VOL</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVERETT_HERBERT</td>\n",
       "      <td>Mas</td>\n",
       "      <td>1</td>\n",
       "      <td>1911</td>\n",
       "      <td>Who Can Blame?</td>\n",
       "      <td>mas0001.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Parade</td>\n",
       "      <td>mas0002.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELDRIDGE_PAUL</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Songs of To-Day</td>\n",
       "      <td>mas0003.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMITH_EDITH</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Mills of the Rich</td>\n",
       "      <td>mas0004.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>Mas</td>\n",
       "      <td>1</td>\n",
       "      <td>1912</td>\n",
       "      <td>At the Terminal</td>\n",
       "      <td>mas0005.txt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUTHOR JOURNAL  MONTH  YEAR             POEM TITLE     FILENAME  \\\n",
       "0   EVERETT_HERBERT     Mas      1  1911         Who Can Blame?  mas0001.txt   \n",
       "1  UNTERMEYER_LOUIS     Mas      7  1912             The Parade  mas0002.txt   \n",
       "2     ELDRIDGE_PAUL     Mas      7  1912    The Songs of To-Day  mas0003.txt   \n",
       "3       SMITH_EDITH     Mas      7  1912  The Mills of the Rich  mas0004.txt   \n",
       "4  UNTERMEYER_LOUIS     Mas      1  1912        At the Terminal  mas0005.txt   \n",
       "\n",
       "   VOL   NO  NOTES  \n",
       "0  1.0  1.0  Added  \n",
       "1  4.0  1.0  Added  \n",
       "2  4.0  1.0  Added  \n",
       "3  4.0  1.0  Added  \n",
       "4  3.0  1.0  Added  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### OK let's get going\n",
    "\n",
    "# First, let's just get to know our data!\n",
    "\n",
    "# Let's read in all the metadata and data\n",
    "# Some necessary imports\n",
    "import pandas as pd\n",
    "\n",
    "# Of course change this variable for your computer\n",
    "path1 = '/Users/richardjeanso/Dropbox/TALKS/EUROPE_2019/WORKSHOP/'\n",
    "meta1 = path1 + 'MassesData.csv'\n",
    "meta2 = path1 + 'OthersData.csv'\n",
    "\n",
    "mass_meta = pd.read_csv(meta1, encoding='latin1')\n",
    "# Let's get rid of any rows that don't have FILENAME\n",
    "mass_meta = mass_meta.dropna(axis=0, subset=['FILENAME'])\n",
    "\n",
    "other_meta = pd.read_csv(meta2, encoding='latin1')\n",
    "other_meta = other_meta.dropna(axis=0, subset=['FILENAME'])\n",
    "\n",
    "# Sanity check\n",
    "#mass_meta.head()\n",
    "#other_meta.head()\n",
    "\n",
    "#mass_meta.shape, other_meta.shape, mass_meta.columns, other_meta.columns\n",
    "mass_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "# This is a really nice data structure but we're not done. Let's read in the actual\n",
    "# text files into the dataframe, and then we'll have ALL of the data (meta + text) in one place!\n",
    "\n",
    "mass_path = '/Users/richardjeanso/Dropbox/TALKS/EUROPE_2019/WORKSHOP/Masses/'\n",
    "other_path = '/Users/richardjeanso/Dropbox/TALKS/EUROPE_2019/WORKSHOP/Others/'\n",
    "\n",
    "import codecs\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "mass_meta['TEXT'] = ''\n",
    "other_meta['TEXT'] = ''\n",
    "\n",
    "for index, row in mass_meta.iterrows():\n",
    "    filepath = mass_path + str(row['FILENAME'])\n",
    "    text = codecs.open(filepath, \"r\")         \n",
    "    raw = text.read()\n",
    "    raw = raw.lower()\n",
    "    raw = ''.join(ch for ch in raw if ch not in exclude)\n",
    "    raw1 = raw.split()\n",
    "    mass_meta.set_value(index, 'TEXT', raw1)\n",
    "    \n",
    "for index, row in other_meta.iterrows():\n",
    "    filepath = other_path + str(row['FILENAME'])\n",
    "    text = codecs.open(filepath, \"r\")         \n",
    "    raw = text.read()\n",
    "    raw = raw.lower()\n",
    "    raw = ''.join(ch for ch in raw if ch not in exclude)\n",
    "    raw1 = raw.split()\n",
    "    other_meta.set_value(index, 'TEXT', raw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POEM TITLE</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>VOL</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVERETT_HERBERT</td>\n",
       "      <td>Mas</td>\n",
       "      <td>1</td>\n",
       "      <td>1911</td>\n",
       "      <td>Who Can Blame?</td>\n",
       "      <td>mas0001.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[who, can, blame, when, the, mills, of, men, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Parade</td>\n",
       "      <td>mas0002.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[the, parade, gay, flags, flying, down, the, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELDRIDGE_PAUL</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Songs of To-Day</td>\n",
       "      <td>mas0003.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[the, songs, of, today, ing, me, the, song, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMITH_EDITH</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Mills of the Rich</td>\n",
       "      <td>mas0004.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[the, mills, of, the, rich, we, ask, that, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>Mas</td>\n",
       "      <td>1</td>\n",
       "      <td>1912</td>\n",
       "      <td>At the Terminal</td>\n",
       "      <td>mas0005.txt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[at, the, terminal, here, where, the, torrent,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUTHOR JOURNAL  MONTH  YEAR             POEM TITLE     FILENAME  \\\n",
       "0   EVERETT_HERBERT     Mas      1  1911         Who Can Blame?  mas0001.txt   \n",
       "1  UNTERMEYER_LOUIS     Mas      7  1912             The Parade  mas0002.txt   \n",
       "2     ELDRIDGE_PAUL     Mas      7  1912    The Songs of To-Day  mas0003.txt   \n",
       "3       SMITH_EDITH     Mas      7  1912  The Mills of the Rich  mas0004.txt   \n",
       "4  UNTERMEYER_LOUIS     Mas      1  1912        At the Terminal  mas0005.txt   \n",
       "\n",
       "   VOL   NO  NOTES                                               TEXT  \n",
       "0  1.0  1.0  Added  [who, can, blame, when, the, mills, of, men, h...  \n",
       "1  4.0  1.0  Added  [the, parade, gay, flags, flying, down, the, s...  \n",
       "2  4.0  1.0  Added  [the, songs, of, today, ing, me, the, song, of...  \n",
       "3  4.0  1.0  Added  [the, mills, of, the, rich, we, ask, that, the...  \n",
       "4  3.0  1.0  Added  [at, the, terminal, here, where, the, torrent,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "mass_meta.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1915.6345177664975, 1916.5263157894738)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK let's learn a bit about our two corpora; let's get a baseline of comparison to understand\n",
    "# how they might be similar or different\n",
    "\n",
    "# First, average year\n",
    "mass_meta['YEAR'].mean(), other_meta['YEAR'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "# Let's next get average length of title + length of poem\n",
    "\n",
    "mass_meta['TITLE_LENGTH'] = ''\n",
    "mass_meta['LENGTH'] = ''\n",
    "other_meta['TITLE_LENGTH'] = ''\n",
    "other_meta['LENGTH'] = ''\n",
    "\n",
    "for index, row in mass_meta.iterrows():\n",
    "    title = len(row['POEM TITLE'].split())\n",
    "    mass_meta.set_value(index, 'TITLE_LENGTH', title)\n",
    "    text = len(row['TEXT'])\n",
    "    mass_meta.set_value(index, 'LENGTH', text)\n",
    "    \n",
    "for index, row in other_meta.iterrows():\n",
    "    title = len(row['POEM TITLE'].split())\n",
    "    other_meta.set_value(index, 'TITLE_LENGTH', title)\n",
    "    text = len(row['TEXT'])\n",
    "    other_meta.set_value(index, 'LENGTH', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POEM TITLE</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>VOL</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TITLE_LENGTH</th>\n",
       "      <th>LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVERETT_HERBERT</td>\n",
       "      <td>Mas</td>\n",
       "      <td>1</td>\n",
       "      <td>1911</td>\n",
       "      <td>Who Can Blame?</td>\n",
       "      <td>mas0001.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[who, can, blame, when, the, mills, of, men, h...</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Parade</td>\n",
       "      <td>mas0002.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[the, parade, gay, flags, flying, down, the, s...</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELDRIDGE_PAUL</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Songs of To-Day</td>\n",
       "      <td>mas0003.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[the, songs, of, today, ing, me, the, song, of...</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMITH_EDITH</td>\n",
       "      <td>Mas</td>\n",
       "      <td>7</td>\n",
       "      <td>1912</td>\n",
       "      <td>The Mills of the Rich</td>\n",
       "      <td>mas0004.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[the, mills, of, the, rich, we, ask, that, the...</td>\n",
       "      <td>5</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>Mas</td>\n",
       "      <td>1</td>\n",
       "      <td>1912</td>\n",
       "      <td>At the Terminal</td>\n",
       "      <td>mas0005.txt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Added</td>\n",
       "      <td>[at, the, terminal, here, where, the, torrent,...</td>\n",
       "      <td>3</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUTHOR JOURNAL  MONTH  YEAR             POEM TITLE     FILENAME  \\\n",
       "0   EVERETT_HERBERT     Mas      1  1911         Who Can Blame?  mas0001.txt   \n",
       "1  UNTERMEYER_LOUIS     Mas      7  1912             The Parade  mas0002.txt   \n",
       "2     ELDRIDGE_PAUL     Mas      7  1912    The Songs of To-Day  mas0003.txt   \n",
       "3       SMITH_EDITH     Mas      7  1912  The Mills of the Rich  mas0004.txt   \n",
       "4  UNTERMEYER_LOUIS     Mas      1  1912        At the Terminal  mas0005.txt   \n",
       "\n",
       "   VOL   NO  NOTES                                               TEXT  \\\n",
       "0  1.0  1.0  Added  [who, can, blame, when, the, mills, of, men, h...   \n",
       "1  4.0  1.0  Added  [the, parade, gay, flags, flying, down, the, s...   \n",
       "2  4.0  1.0  Added  [the, songs, of, today, ing, me, the, song, of...   \n",
       "3  4.0  1.0  Added  [the, mills, of, the, rich, we, ask, that, the...   \n",
       "4  3.0  1.0  Added  [at, the, terminal, here, where, the, torrent,...   \n",
       "\n",
       "  TITLE_LENGTH LENGTH  \n",
       "0            3     79  \n",
       "1            2    200  \n",
       "2            4    300  \n",
       "3            5    232  \n",
       "4            3    201  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "mass_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142.6802030456853, 119.85575048732943)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, compute average title length, average text length\n",
    "#mass_meta['TITLE_LENGTH'].mean(), other_meta['TITLE_LENGTH'].mean()\n",
    "mass_meta['LENGTH'].mean(), other_meta['LENGTH'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6311336717428087, 2.3157894736842106)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_meta['TITLE_LENGTH'].mean(), other_meta['TITLE_LENGTH'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84324,\n",
       " ['who', 'can', 'blame', 'when', 'the'],\n",
       " 61486,\n",
       " ['songs', 'of', 'a', 'girl', 'i'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get some more information, working at the full corpus level\n",
    "\n",
    "all_mass = []\n",
    "\n",
    "for index, row in mass_meta.iterrows():\n",
    "    all_mass.append(row['TEXT'])\n",
    "    \n",
    "all_mass = [item for sublist in all_mass for item in sublist]\n",
    "\n",
    "all_other = []\n",
    "\n",
    "for index, row in other_meta.iterrows():\n",
    "    all_other.append(row['TEXT'])\n",
    "    \n",
    "all_other = [item for sublist in all_other for item in sublist]\n",
    "\n",
    "# Sanity check\n",
    "len(all_mass), all_mass[0:5], len(all_other), all_other[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13205018737251553, 0.14904205835474743)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get Type-Token Ratio (TTR) for both corpora\n",
    "\n",
    "TTR_mass = len(set(all_mass)) / len(all_mass)\n",
    "TTR_other = len(set(all_other)) / len(all_other)\n",
    "\n",
    "TTR_mass, TTR_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('the', 5482),\n",
       "  ('and', 3817),\n",
       "  ('of', 2535),\n",
       "  ('a', 1826),\n",
       "  ('to', 1602),\n",
       "  ('i', 1403),\n",
       "  ('in', 1278),\n",
       "  ('that', 923),\n",
       "  ('you', 838),\n",
       "  ('with', 836)],\n",
       " [('the', 4019),\n",
       "  ('and', 2134),\n",
       "  ('of', 1989),\n",
       "  ('a', 1613),\n",
       "  ('i', 1217),\n",
       "  ('in', 1118),\n",
       "  ('to', 1090),\n",
       "  ('you', 854),\n",
       "  ('is', 671),\n",
       "  ('with', 645)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's identify the most common words in each corpus\n",
    "\n",
    "from collections import Counter\n",
    "mass_counts = Counter(all_mass)\n",
    "other_counts = Counter(all_other)\n",
    "\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "\n",
    "# And then some simple counting\n",
    "ranked_mass = sorted(mass_counts.items(), key=itemgetter(1), reverse=True)\n",
    "ranked_other = sorted(other_counts.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "ranked_mass[0:10], ranked_other[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('little', 205),\n",
       "  ('old', 169),\n",
       "  ('god', 162),\n",
       "  ('men', 158),\n",
       "  ('eyes', 158),\n",
       "  ('life', 148),\n",
       "  ('night', 140),\n",
       "  ('day', 139),\n",
       "  ('heart', 134),\n",
       "  ('light', 113)],\n",
       " [('night', 185),\n",
       "  ('little', 149),\n",
       "  ('eyes', 148),\n",
       "  ('old', 146),\n",
       "  ('white', 139),\n",
       "  ('light', 96),\n",
       "  ('life', 93),\n",
       "  ('wind', 89),\n",
       "  ('men', 79),\n",
       "  ('heart', 78)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After removing stopwords\n",
    "\n",
    "text_file = open(\"/Users/richardjeanso/Dropbox/STACK/STACK_AUX/jockers_stopwords.txt\", \"r\")\n",
    "jockers_words = text_file.read().split()\n",
    "\n",
    "all_mass2 = [word for word in all_mass if word not in jockers_words]\n",
    "all_other2 = [word for word in all_other if word not in jockers_words]\n",
    "\n",
    "mass_counts2 = Counter(all_mass2)\n",
    "other_counts2 = Counter(all_other2)\n",
    "\n",
    "ranked_mass2 = sorted(mass_counts2.items(), key=itemgetter(1), reverse=True)\n",
    "ranked_other2 = sorted(other_counts2.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "ranked_mass2[0:10], ranked_other2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok one more thing; let's determine which words are in MASS but not OTHER and vice versa!\n",
    "\n",
    "mass_not_other = []\n",
    "\n",
    "for word in all_mass2:\n",
    "    if word not in all_other2:\n",
    "        mass_not_other.append(word)\n",
    "        \n",
    "other_not_mass = []\n",
    "\n",
    "for word in all_other2:\n",
    "    if word not in all_mass2:\n",
    "        other_not_mass.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9288, 5774)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mass_not_other), len(other_not_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('toil', 29),\n",
       "  ('th', 26),\n",
       "  ('heartbreak', 16),\n",
       "  ('babies', 15),\n",
       "  ('bloody', 14),\n",
       "  ('workers', 13),\n",
       "  ('blows', 13),\n",
       "  ('driggs', 13),\n",
       "  ('win', 12),\n",
       "  ('bullet', 12)],\n",
       " [('crate', 17),\n",
       "  ('tum', 16),\n",
       "  ('revenge', 14),\n",
       "  ('opus', 13),\n",
       "  ('beads', 11),\n",
       "  ('design', 9),\n",
       "  ('columbine', 9),\n",
       "  ('bushes', 9),\n",
       "  ('woven', 8),\n",
       "  ('prose', 8)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_counts3 = Counter(mass_not_other)\n",
    "other_counts3 = Counter(other_not_mass)\n",
    "\n",
    "ranked_mass3 = sorted(mass_counts3.items(), key=itemgetter(1), reverse=True)\n",
    "ranked_other3 = sorted(other_counts3.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "ranked_mass3[0:10], ranked_other3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SUMMARY\n",
    "# OK that's enough of that surface analysis!\n",
    "# So we know a few things now about these two corpora and how they are similar/different\n",
    "# We know about their average years; their average title and poem lengths\n",
    "# About their basic lexical diversity/repetitiveness, and total number of words\n",
    "# Which words are most common and which words are in one corpus and not in another\n",
    "\n",
    "## This is important to start developing a basic intuition as to these two corpora before we do\n",
    "# more complex analysis, i.e. classification. Before we throw a complex model at the data and we\n",
    "# develop layers of mediation, I think it's important to first know what's there more directly,\n",
    "# before we run all the data through a machine learning algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK let's start classification\n",
    "\n",
    "# First let's merge our two metadata dataframes into one\n",
    "\n",
    "all_meta = pd.concat([mass_meta, other_meta])\n",
    "# Sanity check\n",
    "mass_meta.shape, other_meta.shape, all_meta.shape\n",
    "all_meta = all_meta.reset_index()\n",
    "all_meta = all_meta.drop('index', 1)\n",
    "all_meta.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK next we have to build the document text matrix (DTM) for classification\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus_path = '/Users/richardjeanso/Dropbox/TALKS/EUROPE_2019/WORKSHOP/ALL_TEXTS'\n",
    "\n",
    "# Build DTM\n",
    "vectorizer = CountVectorizer(input='filename', stop_words=jockers_words, min_df=3, encoding='utf8')\n",
    "dtm = vectorizer.fit_transform(corpus_path + \"/\" + all_meta['FILENAME'])\n",
    "vocab = vectorizer.get_feature_names()\n",
    "matrix = dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1104, 4072), 4072, (1104, 5))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "matrix.shape, len(vocab), all_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things are about to get complicated so let's first reduce our metadata to just what we need\n",
    "all_meta = all_meta[['AUTHOR', 'JOURNAL', 'YEAR', 'POEM TITLE', 'FILENAME']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abundant</th>\n",
       "      <th>accents</th>\n",
       "      <th>ache</th>\n",
       "      <th>aches</th>\n",
       "      <th>achieve</th>\n",
       "      <th>...</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zest</th>\n",
       "      <th>äî</th>\n",
       "      <th>äîthis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  able  abroad  absolute  absurd  abundant  accents  ache  aches  \\\n",
       "0        0     0       0         0       0         0        0     0      0   \n",
       "1        0     0       0         0       0         0        0     0      0   \n",
       "2        0     0       0         0       0         0        0     0      0   \n",
       "3        0     0       0         0       0         0        0     0      0   \n",
       "4        0     0       0         0       0         0        0     0      0   \n",
       "\n",
       "   achieve   ...    yield  yielding  yonder  york  young  younger  youth  \\\n",
       "0        0   ...        0         0       0     0      0        0      0   \n",
       "1        0   ...        0         0       0     0      0        0      0   \n",
       "2        0   ...        0         0       0     0      0        0      0   \n",
       "3        0   ...        0         0       0     0      0        0      0   \n",
       "4        0   ...        0         0       0     0      0        0      0   \n",
       "\n",
       "   zest  äî  äîthis  \n",
       "0     0   0       0  \n",
       "1     0   0       0  \n",
       "2     0   0       0  \n",
       "3     0   0       0  \n",
       "4     0   0       0  \n",
       "\n",
       "[5 rows x 4259 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's merge the DTM with the metadata, so we have everything we need for classification\n",
    "\n",
    "DTM = pd.DataFrame(matrix, columns=vocab)\n",
    "DTM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104, 4264)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([all_meta, DTM], axis=1)\n",
    "final_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more thing, let's turn JOURNAL vals into ints\n",
    "\n",
    "final_df.loc[final_df.JOURNAL == \"Mas\", 'JOURNAL'] = 0\n",
    "\n",
    "final_df.loc[final_df.JOURNAL == \"Oth\", 'JOURNAL'] = 1\n",
    "\n",
    "# So remember, now, Masses is 0 and Others is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports we'll need\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK now we have everything we need for classification/predictive modeling\n",
    "\n",
    "# Let's first do the standard off the shelf classification method\n",
    "\n",
    "# Prepare for Machine Learning\n",
    "\n",
    "X = final_df.iloc[:, 5:].values    # corresponds to where feature columns begin\n",
    "Y = final_df.iloc[:, 1].values # corresponds to where class values are located\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model, only on training set (no test set)\n",
    "\n",
    "# Specify regularization penalties\n",
    "model2 = LogisticRegression(penalty='l1', C=1) # Remember l1 is lasso\n",
    "\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we fit the model with train and test\n",
    "\n",
    "# predict class labels for the test set\n",
    "predicted = model2.predict(X_test)\n",
    "# generate class probabilities\n",
    "probs = model2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5993975903614458\n",
      "0.6585011794592632\n",
      "[[104  61]\n",
      " [ 72  95]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.63      0.61       165\n",
      "          1       0.61      0.57      0.59       167\n",
      "\n",
      "avg / total       0.60      0.60      0.60       332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics; accuracy + ROC\n",
    "print(metrics.accuracy_score(y_test, predicted))\n",
    "print(metrics.roc_auc_score(y_test, probs[:, 1])) # not supported for multiclass model\n",
    "\n",
    "# Confusion matrix, F-1 score\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64864865 0.61538462 0.66063348 0.59545455 0.63636364]\n",
      "0.6312969860028683\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate model with cross-validation\n",
    "\n",
    "scores=cross_val_score(LogisticRegression(penalty='l1', C=1), X, Y, scoring='accuracy', cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features associated with second class (OTHERS)\n",
      "\n",
      "('frozen', 1.0)\n",
      "('frost', 1.0)\n",
      "('frogs', 1.0)\n",
      "('frog', 1.0)\n",
      "('frock', 1.0)\n",
      "('left', 1.0071486749139056)\n",
      "('sun', 1.1128739602346676)\n",
      "('like', 1.1428421733807623)\n",
      "('night', 1.1448037235894455)\n",
      "('white', 1.1851913130503322)\n",
      "\n",
      "\n",
      "Top 10 features associated with first class (MASSES)\n",
      "\n",
      "('man', 0.695883727537714)\n",
      "('ve', 0.7055368070177002)\n",
      "('wonder', 0.7687565439211329)\n",
      "('heart', 0.8377474448477009)\n",
      "('god', 0.8602395949262549)\n",
      "('men', 0.8620419110699767)\n",
      "('war', 0.885674332995567)\n",
      "('free', 0.891336790380091)\n",
      "('day', 0.9040760809473607)\n",
      "('air', 0.9191410695114668)\n"
     ]
    }
   ],
   "source": [
    "# Compute most informative features for binary case\n",
    "\n",
    "clf = LogisticRegression(penalty='l1', C=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "feature_names = final_df.columns[5:].values     \n",
    "class_labels = final_df['JOURNAL'].unique()\n",
    "\n",
    "top20 = np.argsort(np.exp(clf.coef_))[0][-10:]\n",
    "print(\"Top 10 features associated with second class (OTHERS)\\n\")\n",
    "for el in zip(feature_names[top20], np.exp(clf.coef_)[0][top20]):\n",
    "    print(el)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Top 10 features associated with first class (MASSES)\\n\")\n",
    "bottom20 = np.argsort(np.exp(clf.coef_))[0][:10]\n",
    "for el in zip(feature_names[bottom20], np.exp(clf.coef_)[0][bottom20]):\n",
    "    print(el)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
     ]
    }
   ],
   "source": [
    "# NOW I'm going to implement the ONE VS ALL method (mini lecture on that) to produce stable results\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "output = []\n",
    "\n",
    "i=0\n",
    "for i in range(final_df.shape[0]):\n",
    "    print(i)\n",
    "    # First grab all data minus test case, and then, the test case\n",
    "    predict_row = final_df.loc[[i]]\n",
    "    train_rows = final_df.drop(i)\n",
    "    \n",
    "    # Specify logit model, l1 penalty and C=1.0 (standard)\n",
    "    model = LogisticRegression(penalty='l1', C=1)\n",
    "    \n",
    "    # Fit the model\n",
    "    X = train_rows.iloc[:, 5:]\n",
    "    y = train_rows.iloc[:, 1]\n",
    "    TEST_CASE = predict_row.iloc[:, 5:]\n",
    "    true_label = predict_row.iloc[:, 1].values\n",
    "    true_fname = predict_row.iloc[:, 4].values\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict\n",
    "    # predict class labels for the test set\n",
    "    predicted = model.predict(TEST_CASE)\n",
    "    # generate class probabilities\n",
    "    probs = model.predict_proba(TEST_CASE)\n",
    "    \n",
    "    # Save output\n",
    "    output.append((str(true_fname), str(true_label), str(predicted), probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"['mas0001.txt']\", '[0]', '[0]', array([[0.65192123, 0.34807877]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "output[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's parse this output so we can analyze it\n",
    "\n",
    "files = []\n",
    "trues = []\n",
    "predicts = []\n",
    "probs = []\n",
    "\n",
    "for item in output:\n",
    "    files.append(item[0])\n",
    "    trues.append(item[1])\n",
    "    predicts.append(item[2])\n",
    "    probs.append(item[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>TRUE_CLASS</th>\n",
       "      <th>PREDICT_CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['mas0001.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mas0002.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['mas0003.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['mas0004.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['mas0005.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FILENAME TRUE_CLASS PREDICT_CLASS\n",
       "0  ['mas0001.txt']        [0]           [0]\n",
       "1  ['mas0002.txt']        [0]           [0]\n",
       "2  ['mas0003.txt']        [0]           [0]\n",
       "3  ['mas0004.txt']        [0]           [0]\n",
       "4  ['mas0005.txt']        [0]           [0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe for easy viewing\n",
    "df = pd.DataFrame(files, columns=['FILENAME'])\n",
    "df['TRUE_CLASS'] = trues\n",
    "df['PREDICT_CLASS'] = predicts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob values are still messy, we need to clean them\n",
    "\n",
    "import re\n",
    "probs3A = []\n",
    "probs3B = []\n",
    "\n",
    "for prob in probs:\n",
    "    x = prob.tolist()\n",
    "    probs3A.append(x[0][0])\n",
    "    probs3B.append(x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>TRUE_CLASS</th>\n",
       "      <th>PREDICT_CLASS</th>\n",
       "      <th>PROB_MASS</th>\n",
       "      <th>PROB_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['mas0001.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.651921</td>\n",
       "      <td>0.348079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mas0002.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.931050</td>\n",
       "      <td>0.068950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['mas0003.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['mas0004.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['mas0005.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.993927</td>\n",
       "      <td>0.006073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FILENAME TRUE_CLASS PREDICT_CLASS  PROB_MASS  PROB_OTHER\n",
       "0  ['mas0001.txt']        [0]           [0]   0.651921    0.348079\n",
       "1  ['mas0002.txt']        [0]           [0]   0.931050    0.068950\n",
       "2  ['mas0003.txt']        [0]           [0]   0.999794    0.000206\n",
       "3  ['mas0004.txt']        [0]           [0]   0.999891    0.000109\n",
       "4  ['mas0005.txt']        [0]           [0]   0.993927    0.006073"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put into dataframe\n",
    "df['PROB_MASS'] = probs3A\n",
    "df['PROB_OTHER'] = probs3B\n",
    "# Sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Let's do some analysis. First let's determine how accurate the classifier is\n",
    "# by computing the rate of misclassifieds, and let's also identify those misclassifieds\n",
    "\n",
    "df['RESULT'] = ''\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['TRUE_CLASS'] != row['PREDICT_CLASS']:\n",
    "        df.set_value(index, 'RESULT', 'FALSE')\n",
    "    else:\n",
    "        df.set_value(index, 'RESULT', 'CORRECT')\n",
    "        \n",
    "misclassifieds = df[df['RESULT'] == 'FALSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603260869565217"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple stuff, compute overall accuracy of classifier\n",
    "\n",
    "corrects = df[df['RESULT'] == 'CORRECT']\n",
    "accuracy = corrects.shape[0] / df.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>TRUE_CLASS</th>\n",
       "      <th>PREDICT_CLASS</th>\n",
       "      <th>PROB_MASS</th>\n",
       "      <th>PROB_OTHER</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>['mas0206.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>5.399949e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>['mas0197.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>6.225487e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>['oth0386.txt']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>5.841763e-06</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>['mas0440.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.078103e-05</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>['oth0153.txt']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.623651e-04</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>['oth0226.txt']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2.304107e-04</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>['oth0474.txt']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2.638896e-04</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>['oth0420.txt']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>3.004039e-04</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>['oth0022.txt']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>3.886933e-04</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>['mas0545.txt']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>6.346932e-04</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FILENAME TRUE_CLASS PREDICT_CLASS     PROB_MASS  PROB_OTHER  \\\n",
       "205   ['mas0206.txt']        [0]           [1]  5.399949e-10    1.000000   \n",
       "196   ['mas0197.txt']        [0]           [1]  6.225487e-10    1.000000   \n",
       "976   ['oth0386.txt']        [1]           [1]  5.841763e-06    0.999994   \n",
       "439   ['mas0440.txt']        [0]           [1]  1.078103e-05    0.999989   \n",
       "743   ['oth0153.txt']        [1]           [1]  1.623651e-04    0.999838   \n",
       "816   ['oth0226.txt']        [1]           [1]  2.304107e-04    0.999770   \n",
       "1064  ['oth0474.txt']        [1]           [1]  2.638896e-04    0.999736   \n",
       "1010  ['oth0420.txt']        [1]           [1]  3.004039e-04    0.999700   \n",
       "612   ['oth0022.txt']        [1]           [1]  3.886933e-04    0.999611   \n",
       "544   ['mas0545.txt']        [0]           [1]  6.346932e-04    0.999365   \n",
       "\n",
       "       RESULT  \n",
       "205     FALSE  \n",
       "196     FALSE  \n",
       "976   CORRECT  \n",
       "439     FALSE  \n",
       "743   CORRECT  \n",
       "816   CORRECT  \n",
       "1064  CORRECT  \n",
       "1010  CORRECT  \n",
       "612   CORRECT  \n",
       "544     FALSE  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Texts most strongly predicted to belong to MASSES or OTHERS\n",
    "\n",
    "mass_df = df.sort_values(by=['PROB_MASS'], ascending=False)\n",
    "other_df = df.sort_values(by=['PROB_OTHER'], ascending=False)\n",
    "other_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Exercise! That's interesting MAS0206 is so strongly predicted to be OTHERS!\n",
    "# Let's take a look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Let's now look at specific feature weights based on the model\n",
    "# The idea is that we want a bit more granularity as to what specific features are driving our classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need some functions to help us compute these feature weights\n",
    "\n",
    "# Simple function to compute Z-score\n",
    "\n",
    "def Ztest(vec1, vec2):\n",
    "    # edited from https://stats.stackexchange.com/questions/124096/two-samples-z-test-in-python\n",
    "    \n",
    "    X1, X2 = np.mean(vec1), np.mean(vec2)\n",
    "    sd1, sd2 = np.std(vec1), np.std(vec2)\n",
    "    n1, n2 = len(vec1), len(vec2)\n",
    "    \n",
    "    pooledSE = np.sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = (X1 - X2)/pooledSE\n",
    "    pval = 2*(norm.sf(abs(z)))\n",
    "    \n",
    "    return z, pval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another function to compute logistic regression weights on each feature (also does Z-test)\n",
    "\n",
    "canonic_c = 1.0 # value returning best f1\n",
    "\n",
    "def feat_pval_weight(meta_df_, dtm_df_):\n",
    "    # Split dtms for ease in pipeline\n",
    "    \n",
    "    dtm_df_ = dtm_df_.loc[meta_df_.index.tolist()]\n",
    "    dtm_df_ = normalize_model(dtm_df_, dtm_df_)[0]\n",
    "    dtm_df_ = dtm_df_.dropna(axis=1, how='any')\n",
    "    \n",
    "    best_dtm = dtm_df_.loc[meta_df_[meta_df_['JOURNAL']=='Mas'].index.tolist()].as_matrix()\n",
    "    black_dtm = dtm_df_.loc[meta_df_[meta_df_['JOURNAL']=='Oth'].index.tolist()].as_matrix()\n",
    "    \n",
    "    pvals = [Ztest(best_dtm[:,i],black_dtm[:,i])[1] for i in range(dtm_df_.shape[1])]\n",
    "    \n",
    "    clf = LogisticRegression(penalty='l1', C=canonic_c, class_weight = 'balanced')\n",
    "    clf.fit(dtm_df_, meta_df_['JOURNAL']=='Mas')\n",
    "    weights = clf.coef_[0]\n",
    "    \n",
    "    feature_df = pd.DataFrame()\n",
    "    \n",
    "    feature_df['FEAT'] = dtm_df_.columns\n",
    "    feature_df['P_VALUE'] = pvals\n",
    "    feature_df['LR_WEIGHT'] = weights\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's probably a good idea to turn all the values in the DTM to standard units; that's what this function does\n",
    "\n",
    "def normalize_model(train_df_, test_df_):\n",
    "    \n",
    "    # Normalize each value by the sum of all values in its row\n",
    "    train_df_ = train_df_.apply(lambda x: x/sum(x), axis=1)\n",
    "    test_df_ = test_df_.apply(lambda x: x/sum(x), axis=1)\n",
    "    \n",
    "    # Get mean and stdev for each column\n",
    "    train_mean = np.mean(train_df_)\n",
    "    train_std = np.std(train_df_)\n",
    "\n",
    "    # Transform each value to standard units for its column\n",
    "    train_df_ = ( train_df_ - train_mean ) / train_std\n",
    "    test_df_ = ( test_df_ - train_mean ) / train_std\n",
    "    \n",
    "    train_df_ = train_df_.dropna(axis=1, how='any')\n",
    "    test_df_ = test_df_[train_df_.columns]\n",
    "    \n",
    "    return train_df_, test_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1104, 5), (1104, 4259))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "all_meta.shape, DTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonferroni adjustment\n",
    "sig_thresh = 0.01 #/ len(DTM.columns) Usually we use bonferri correction with so many features but for some reason\n",
    "# this wasn't necessary for this dataset, probably because this set is relatively small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4259, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature report\n",
    "import numpy as np\n",
    "feat_df = feat_pval_weight(all_meta, DTM)\n",
    "feat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP OTHER TEXT FEATURES: \n",
      "like\n",
      "sun\n",
      "night\n",
      "stone\n",
      "ii\n",
      "fallen\n",
      "falling\n",
      "opus\n",
      "darkness\n",
      "silence\n",
      "swift\n",
      "leaves\n",
      "gold\n",
      "iii\n",
      "calls\n",
      "strife\n",
      "iv\n",
      "lucky\n",
      "thou\n",
      "win\n"
     ]
    }
   ],
   "source": [
    "# Feature Report, TOP 25\n",
    "\n",
    "out = feat_df[ (feat_df['P_VALUE'] <= sig_thresh ) ].sort_values('LR_WEIGHT', ascending=True)\n",
    "# True is OTHER, False is MASS\n",
    "\n",
    "out2 = out['FEAT'].tolist()\n",
    "top_feats = out2[0:20]\n",
    "print(\"TOP OTHER TEXT FEATURES: \")\n",
    "#print(\"TOP MASSES TEXT FEATURES: \")\n",
    "for o in top_feats:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Close reading!\n",
    "# Let's go back to that MASSES text that was misclassified confidently to be an OTHERS text\n",
    "# Now we have a foundation or a better basis to close read it; we know the specific words \n",
    "# that are important in classifying it as OTHERS rather than MASSES, it's actual identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so that's just some basic stuff we can do with classification/predictive modeling with a 2 class example\n",
    "# Obviously there is a ton more we can do; for example, in the lecture I gave on \"Race and Distant Reading,\"\n",
    "# I look at the feature variance between our two classes, and show how one group is far more variant than\n",
    "# the other. There's a lot more one can do with this method, of course, for literary studies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to do one more thing though. I increasingly find it useful to approach one's data from multiple perspectives,\n",
    "# to use multiple methods to see how different models understand the data.\n",
    "# There's another way we can determine the semantic differences between two groups of texts that is far simpler than\n",
    "# classification.\n",
    "# We can simply use a most distinctive words test.\n",
    "# So let's try that, just to see what kind of differnet results this produces versus our classification exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the Mann Whitney U test\n",
    "# A good overview/explanation and rationale for literary texts/poems is here:\n",
    "# https://tedunderwood.com/2011/11/09/identifying-the-terms-that-\n",
    "# characterize-an-author-or-genre-why-dunnings-may-not-be-the-best-method/\n",
    "\n",
    "# Key point: \"In general, it gives less weight to raw frequency, and more weight to \n",
    "# the relative ubiquity of a term in different corpora.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POEM TITLE</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>abandon</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absurd</th>\n",
       "      <th>...</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zest</th>\n",
       "      <th>äî</th>\n",
       "      <th>äîthis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVERETT_HERBERT</td>\n",
       "      <td>0</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>Who Can Blame?</td>\n",
       "      <td>mas0001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>The Parade</td>\n",
       "      <td>mas0002.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELDRIDGE_PAUL</td>\n",
       "      <td>0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>The Songs of To-Day</td>\n",
       "      <td>mas0003.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMITH_EDITH</td>\n",
       "      <td>0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>The Mills of the Rich</td>\n",
       "      <td>mas0004.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNTERMEYER_LOUIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>At the Terminal</td>\n",
       "      <td>mas0005.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUTHOR  JOURNAL    YEAR             POEM TITLE     FILENAME  \\\n",
       "0   EVERETT_HERBERT        0  1911.0         Who Can Blame?  mas0001.txt   \n",
       "1  UNTERMEYER_LOUIS        0  1912.0             The Parade  mas0002.txt   \n",
       "2     ELDRIDGE_PAUL        0  1912.0    The Songs of To-Day  mas0003.txt   \n",
       "3       SMITH_EDITH        0  1912.0  The Mills of the Rich  mas0004.txt   \n",
       "4  UNTERMEYER_LOUIS        0  1912.0        At the Terminal  mas0005.txt   \n",
       "\n",
       "   abandon  able  abroad  absolute  absurd   ...    yield  yielding  yonder  \\\n",
       "0        0     0       0         0       0   ...        0         0       0   \n",
       "1        0     0       0         0       0   ...        0         0       0   \n",
       "2        0     0       0         0       0   ...        0         0       0   \n",
       "3        0     0       0         0       0   ...        0         0       0   \n",
       "4        0     0       0         0       0   ...        0         0       0   \n",
       "\n",
       "   york  young  younger  youth  zest  äî  äîthis  \n",
       "0     0      0        0      0     0   0       0  \n",
       "1     0      0        0      0     0   0       0  \n",
       "2     0      0        0      0     0   0       0  \n",
       "3     0      0        0      0     0   0       0  \n",
       "4     0      0        0      0     0   0       0  \n",
       "\n",
       "[5 rows x 4264 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first call up our data\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((591, 4264), (513, 4264))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to split our corpora back into MASSES and OTHERS again\n",
    "# This is the format my Mann Whitney U test function takes\n",
    "\n",
    "corpus1 = final_df[final_df['JOURNAL'] == 0]\n",
    "corpus2 = final_df[final_df['JOURNAL'] == 1]\n",
    "\n",
    "corpus1.shape, corpus2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abundant</th>\n",
       "      <th>accents</th>\n",
       "      <th>ache</th>\n",
       "      <th>aches</th>\n",
       "      <th>achieve</th>\n",
       "      <th>...</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yonder</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zest</th>\n",
       "      <th>äî</th>\n",
       "      <th>äîthis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  able  abroad  absolute  absurd  abundant  accents  ache  aches  \\\n",
       "0        0     0       0         0       0         0        0     0      0   \n",
       "1        0     0       0         0       0         0        0     0      0   \n",
       "2        0     0       0         0       0         0        0     0      0   \n",
       "3        0     0       0         0       0         0        0     0      0   \n",
       "4        0     0       0         0       0         0        0     0      0   \n",
       "\n",
       "   achieve   ...    yield  yielding  yonder  york  young  younger  youth  \\\n",
       "0        0   ...        0         0       0     0      0        0      0   \n",
       "1        0   ...        0         0       0     0      0        0      0   \n",
       "2        0   ...        0         0       0     0      0        0      0   \n",
       "3        0   ...        0         0       0     0      0        0      0   \n",
       "4        0   ...        0         0       0     0      0        0      0   \n",
       "\n",
       "   zest  äî  äîthis  \n",
       "0     0   0       0  \n",
       "1     0   0       0  \n",
       "2     0   0       0  \n",
       "3     0   0       0  \n",
       "4     0   0       0  \n",
       "\n",
       "[5 rows x 4259 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's slice both corpora now to just get the word counts\n",
    "\n",
    "corpus1A = corpus1.iloc[:, 5:]\n",
    "corpus2A = corpus2.iloc[:, 5:]\n",
    "corpus1A.shape, corpus2A.shape\n",
    "corpus1A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
     ]
    }
   ],
   "source": [
    "# Let's run the mann whitney utest\n",
    "# NB: For a function that takes some time, I like to see its progress, thus the i counter\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "i = 0\n",
    "out = []\n",
    "for column in corpus1A:\n",
    "    print(i)\n",
    "    vals = corpus1A[column].values\n",
    "    vals2 = corpus2A[column].values\n",
    "    mw = mannwhitneyu(vals, vals2)\n",
    "    mwStat = mw.statistic\n",
    "    mwRho = mwStat / corpus1A.shape[0] * corpus2A.shape[0]\n",
    "    out.append((column, mwStat, mwRho))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4259"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit into a dataframe\n",
    "words = []\n",
    "rho = []\n",
    "\n",
    "for item in out:\n",
    "    words.append(item[0])\n",
    "    rho.append(item[2])\n",
    "    \n",
    "mdw_df = pd.DataFrame(words, columns=['WORD'])\n",
    "mdw_df['MDW_RHO'] = rho\n",
    "len(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "      <th>MDW_RHO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>asleep</td>\n",
       "      <td>131576.253807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>wing</td>\n",
       "      <td>131571.045685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>press</td>\n",
       "      <td>131568.007614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>huge</td>\n",
       "      <td>131568.007614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>carry</td>\n",
       "      <td>131565.837563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>pretty</td>\n",
       "      <td>131565.837563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>bend</td>\n",
       "      <td>131564.969543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>cheek</td>\n",
       "      <td>131564.101523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>fools</td>\n",
       "      <td>131562.799492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>growing</td>\n",
       "      <td>131562.365482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>talking</td>\n",
       "      <td>131562.365482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>sought</td>\n",
       "      <td>131559.761421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>hill</td>\n",
       "      <td>131555.855330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>sound</td>\n",
       "      <td>131552.383249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>square</td>\n",
       "      <td>131541.098985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>mud</td>\n",
       "      <td>131538.928934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>tongue</td>\n",
       "      <td>131536.324873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>mystery</td>\n",
       "      <td>131536.324873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>gives</td>\n",
       "      <td>131536.324873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>use</td>\n",
       "      <td>131535.456853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WORD        MDW_RHO\n",
       "120    asleep  131576.253807\n",
       "4145     wing  131571.045685\n",
       "2693    press  131568.007614\n",
       "1768     huge  131568.007614\n",
       "489     carry  131565.837563\n",
       "2699   pretty  131565.837563\n",
       "236      bend  131564.969543\n",
       "548     cheek  131564.101523\n",
       "1348    fools  131562.799492\n",
       "1596  growing  131562.365482\n",
       "3656  talking  131562.365482\n",
       "3342   sought  131559.761421\n",
       "1715     hill  131555.855330\n",
       "3345    sound  131552.383249\n",
       "3409   square  131541.098985\n",
       "2324      mud  131538.928934\n",
       "3784   tongue  131536.324873\n",
       "2343  mystery  131536.324873\n",
       "1490    gives  131536.324873\n",
       "3941      use  131535.456853"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = mdw_df.sort_values(\"MDW_RHO\", ascending=False)\n",
    "# False is MASSES, True is OTHERS\n",
    "df2[0:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What do you make of these results compared to the classification feature results?\n",
    "# What's your intuition as to why we got these results based on what you know of the model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
